# -*- coding: utf-8 -*-
"""final_results_gender_test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/MITESHPUTHRANNEU/Speech-Emotion-Analyzer/blob/master/final_results_gender_test.ipynb


## Importing the required libraries
"""


import librosa
import librosa.display

import numpy as np

import matplotlib.pyplot as plt, IPython.display as ipd

import tensorflow as tf

import os
import pandas as pd
import glob 
import scipy.io.wavfile
import sys
import json
import random

import soundfile
import pickle
import tqdm


from tensorflow import keras

from matplotlib.pyplot import specgram
from tensorflow.keras.preprocessing import sequence
from tensorflow.keras.models import Sequential
from tensorflow.keras.models import model_from_json
from tensorflow.keras.layers import LSTM
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.utils import to_categorical
from tensorflow.keras import Input
from tensorflow.keras import layers
from tensorflow.keras import models




from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, BatchNormalization, MaxPooling2D,GlobalAveragePooling2D,Input
from tensorflow.keras.layers import AveragePooling2D
from tensorflow.keras.layers import LeakyReLU
from tensorflow.keras import optimizers
from tensorflow.keras.optimizers import Adam

from tensorflow.python.keras.applications.resnet import ResNet50
from tensorflow.python.keras.models import Sequential
from tensorflow.python.keras.layers import Dense

from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.callbacks import CSVLogger
from sklearn.metrics import confusion_matrix
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import LabelBinarizer
from sklearn.preprocessing import MultiLabelBinarizer

from sklearn.utils import shuffle

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.neural_network import MLPClassifier

from datetime import datetime




mylist= os.listdir('RawData/')


data, sampling_rate = librosa.load('RawData/01-01-01-01-01-01-01.wav')

print(type(data), type(sampling_rate))

print('data.shape',data.shape)
print('sampling_rate',sampling_rate)



plt.figure(figsize=(14, 5))
librosa.display.waveplot(data, sr=sampling_rate)

plt.show()




# stft

plt.figure(figsize=(15, 5))
librosa.display.waveplot(data, sr=sampling_rate)
sr,x = scipy.io.wavfile.read('RawData/01-01-01-01-01-01-01.wav')

print('sr',sr)

print('x',x.shape)

hop_length = 441
n_fft = 512
D = librosa.stft(data, n_fft=n_fft, hop_length=hop_length)

#float(hop_length)/sr # units of seconds
#float(n_fft)/sr  # units of seconds

print('D',D.shape)


print('\n')

S = librosa.amplitude_to_db(abs(D))

print('S',S)
print(S.shape)

plt.figure(figsize=(15, 5))
librosa.display.specshow(S, sr=sr, hop_length=hop_length, x_axis='time', y_axis='linear')
plt.colorbar(format='%+2.0f dB')

plt.show()
print('\n stft.shape')
print(S.shape)


df = pd.DataFrame(columns=['feature'])
bookmark = 0

hop_length = 441
n_fft = 512

feeling_list = []

for index,y in enumerate(mylist):
   
    if mylist[index][6:-16]!='01' and mylist[index][6:-16]!='07' and mylist[index][6:-16]!='08' and mylist[index][:2]!='su' and                mylist[index][:1]!='n' and mylist[index][:1]!='d':
           X, sample_rate = librosa.load('RawData/'+y, res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)
           # STFT
           D  = librosa.stft(X, n_fft=n_fft, hop_length=hop_length)
           
           S = librosa.amplitude_to_db(abs(D))
          
           #if S.shape != (257, 251) :
             # print("Audio file: ", y)
              #input('')
             
           if S.shape != (257, 251):
               continue
           feature = S
           df.loc[bookmark] = [feature]
           bookmark=bookmark+1
           item = mylist[index]
           if item[6:-16]=='02' and int(item[18:-4])%2==0:
               feeling_list.append('female_calm')
           elif item[6:-16]=='02' and int(item[18:-4])%2==1:
               feeling_list.append('male_calm')
           elif item[6:-16]=='03' and int(item[18:-4])%2==0:
               feeling_list.append('female_happy')
           elif item[6:-16]=='03' and int(item[18:-4])%2==1:
               feeling_list.append('male_happy')
           elif item[6:-16]=='04' and int(item[18:-4])%2==0:
               feeling_list.append('female_sad')
           elif item[6:-16]=='04' and int(item[18:-4])%2==1:
               feeling_list.append('male_sad')
           elif item[6:-16]=='05' and int(item[18:-4])%2==0:
               feeling_list.append('female_angry')
           elif item[6:-16]=='05' and int(item[18:-4])%2==1:
               feeling_list.append('male_angry')
           elif item[6:-16]=='06' and int(item[18:-4])%2==0:
               feeling_list.append('female_fearful')
           elif item[6:-16]=='06' and int(item[18:-4])%2==1:
               feeling_list.append('male_fearful')
           elif item[:1]=='a':
               feeling_list.append('male_angry')
           elif item[:1]=='f':
               feeling_list.append('male_fearful')
           elif item[:1]=='h':
               feeling_list.append('male_happy')
           #elif item[:1]=='n':
           #feeling_list.append('neutral')
           elif item[:2]=='sa':
               feeling_list.append('male_sad')

labels = pd.DataFrame(feeling_list)


print(df.shape,labels.shape)

x = np.array(df.feature.tolist())

print(x.shape)

y=labels.to_numpy().ravel()
print('y.shape',y.shape)


lb = LabelEncoder()


yy = to_categorical(lb.fit_transform(y))

print('y_train',yy.shape)


x_train, x_test, y_train, y_test = train_test_split(x, yy, test_size=0.20, random_state = 42)



print('x_train', x_train.shape)
print('x_test' , x_test.shape)
print('y_train', y_train.shape)
print('y_test' , y_test.shape)

x_train[0].flatten()

x_traincnn =np.expand_dims(x_train, axis=2)
x_testcnn= np.expand_dims(x_test, axis=2)

print('x_traincnn',x_traincnn.shape)

num_rows     = 257
num_columns  = 251
num_channels = 1



leaky_relu_alpha = 0.1
filter_size = 2

x_train = x_train.reshape(x_train.shape[0],num_rows,num_columns,num_channels)
x_test  = x_test.reshape(x_test.shape[0],num_rows,num_columns,num_channels)


print('new_train',x_train.shape)

num_labels = yy.shape[1]

# Construct model 
model = Sequential()

# Construct model 
model = Sequential()
model.add(Conv2D(filters=16, kernel_size= (5,5), padding = 'same',input_shape=(num_rows, num_columns, num_channels)))
model.add(LeakyReLU(alpha=leaky_relu_alpha))

model.add(Conv2D(filters=32, kernel_size=(3,3), padding = 'same'))
model.add(LeakyReLU(alpha=leaky_relu_alpha))
model.add(MaxPooling2D(pool_size=2))
model.add(BatchNormalization())

model.add(Conv2D(filters=64, kernel_size=(3,3), padding = 'same'))
model.add(LeakyReLU(alpha=leaky_relu_alpha))
model.add(MaxPooling2D(pool_size=2))
model.add(BatchNormalization())


model.add(Conv2D(filters=128, kernel_size=(3,3), padding = 'same'))
model.add(LeakyReLU(alpha=leaky_relu_alpha))
model.add(MaxPooling2D(pool_size=2))
model.add(BatchNormalization())

model.add(Flatten())

model.add(Dense(num_labels, activation='softmax'))


# Display model architecture summary 
model.summary()

# Compile the model
model.compile(loss='categorical_crossentropy', metrics=['categorical_accuracy'], optimizer='adam')

print(model)


# Calculate pre-training accuracy 
score = model.evaluate(x_test, y_test, verbose=1)
accuracy = 100*score[1]

print("Pre-training accuracy: %.4f%%" % accuracy)

csv_logger = CSVLogger('log.csv', append=True, separator=';')

cnnhistory=model.fit(x_train, y_train, batch_size=16, epochs=700, validation_data=(x_test, y_test),callbacks=[csv_logger])


# Evaluating the model on the training and testing set
score = model.evaluate(x_train, y_train, verbose=0)
print("Training Accuracy: ", score[1])

score = model.evaluate(x_test, y_test, verbose=0)
print("Testing Accuracy: ", score[1])













