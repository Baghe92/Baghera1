# -*- coding: utf-8 -*-
"""final_results_gender_test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/MITESHPUTHRANNEU/Speech-Emotion-Analyzer/blob/master/final_results_gender_test.ipynb


## Importing the required libraries
"""


import librosa

import librosa.display

import numpy as np

import matplotlib.pyplot as plt, IPython.display as ipd

import tensorflow as tf

import os
import pandas as pd
import glob 
import scipy.io.wavfile
import sys
import json
import random

import soundfile
import pickle
import tqdm


from tensorflow import keras

from matplotlib.pyplot import specgram
from tensorflow.keras.preprocessing import sequence
from tensorflow.keras.models import Sequential
from tensorflow.keras.models import model_from_json
from tensorflow.keras.layers import LSTM
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.utils import to_categorical
from tensorflow.keras import Input
from tensorflow.keras import layers
from tensorflow.keras import models
from tensorflow.keras.layers import Add
from tensorflow.keras.layers import Concatenate




from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, BatchNormalization, MaxPooling2D,GlobalAveragePooling2D,Input
from tensorflow.keras.layers import AveragePooling2D
from tensorflow.keras.layers import LeakyReLU
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras import optimizers
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.optimizers import RMSprop

#from tensorflow.python.keras.applications.resnet import ResNet50
from tensorflow.python.keras.models import Sequential
from tensorflow.python.keras.layers import Dense

from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.callbacks import CSVLogger
from sklearn.metrics import confusion_matrix
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import LabelBinarizer
from sklearn.preprocessing import MultiLabelBinarizer

from sklearn.utils import shuffle

from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score
from sklearn.neural_network import MLPClassifier

from datetime import datetime




mylist= os.listdir('RawData/')


data, sampling_rate = librosa.load('RawData/01-01-01-01-01-01-01.wav')

print(type(data), type(sampling_rate))

print('data.shape',data.shape)
print('sampling_rate',sampling_rate)



plt.figure(figsize=(14, 5))
librosa.display.waveplot(data, sr=sampling_rate)

plt.show()




# stft

plt.figure(figsize=(15, 5))
librosa.display.waveplot(data, sr=sampling_rate)
sr,x = scipy.io.wavfile.read('RawData/01-01-01-01-01-01-01.wav')

print('sr',sr)

print('x',x.shape)

hop_length = 441
n_fft = 512
D = librosa.stft(data, n_fft=n_fft, hop_length=hop_length)

#float(hop_length)/sr # units of seconds
#float(n_fft)/sr  # units of seconds

print('D',D.shape)


print('\n')

S = librosa.amplitude_to_db(abs(D))

print('S',S)
print(S.shape)

plt.figure(figsize=(15, 5))
librosa.display.specshow(S, sr=sr, hop_length=hop_length, x_axis='time', y_axis='linear')
plt.colorbar(format='%+2.0f dB')

plt.show()
print('\n stft.shape')
print(S.shape)


df = pd.DataFrame(columns=['feature'])
bookmark = 0

hop_length = 441
n_fft = 512

feeling_list = []

for index,y in enumerate(mylist):
   
    if mylist[index][6:-16]!='01' and mylist[index][6:-16]!='07' and mylist[index][6:-16]!='08' and mylist[index][:2]!='su' and                mylist[index][:1]!='n' and mylist[index][:1]!='d':
           X, sample_rate = librosa.load('RawData/'+y, res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)
           # STFT
           D  = librosa.stft(X, n_fft=n_fft, hop_length=hop_length)
           
           S = librosa.amplitude_to_db(abs(D))
          
           #if S.shape != (257, 251) :
             # print("Audio file: ", y)
              #input('')
             
           if S.shape != (257, 251):
               continue
           feature = S
           df.loc[bookmark] = [feature]
           bookmark=bookmark+1
           item = mylist[index]
           if item[6:-16]=='02' and int(item[18:-4])%2==0:
               feeling_list.append('female_calm')
           elif item[6:-16]=='02' and int(item[18:-4])%2==1:
               feeling_list.append('male_calm')
           elif item[6:-16]=='03' and int(item[18:-4])%2==0:
               feeling_list.append('female_happy')
           elif item[6:-16]=='03' and int(item[18:-4])%2==1:
               feeling_list.append('male_happy')
           elif item[6:-16]=='04' and int(item[18:-4])%2==0:
               feeling_list.append('female_sad')
           elif item[6:-16]=='04' and int(item[18:-4])%2==1:
               feeling_list.append('male_sad')
           elif item[6:-16]=='05' and int(item[18:-4])%2==0:
               feeling_list.append('female_angry')
           elif item[6:-16]=='05' and int(item[18:-4])%2==1:
               feeling_list.append('male_angry')
           elif item[6:-16]=='06' and int(item[18:-4])%2==0:
               feeling_list.append('female_fearful')
           elif item[6:-16]=='06' and int(item[18:-4])%2==1:
               feeling_list.append('male_fearful')
           elif item[:1]=='a':
               feeling_list.append('male_angry')
           elif item[:1]=='f':
               feeling_list.append('male_fearful')
           elif item[:1]=='h':
               feeling_list.append('male_happy')
           #elif item[:1]=='n':
           #feeling_list.append('neutral')
           elif item[:2]=='sa':
               feeling_list.append('male_sad')

labels = pd.DataFrame(feeling_list)


print(df.shape,labels.shape)

x = np.array(df.feature.tolist())

print(x.shape)

y=labels.to_numpy().ravel()
print('y.shape',y.shape)

#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state = 42)

skf = StratifiedKFold(n_splits = 10)
skf.get_n_splits(x, y)

print(skf)

StratifiedKFold(n_splits = 10, random_state=None, shuffle=False)

for train_index, test_index in skf.split(x, y):
	print("TRAIN:", train_index, "TEST:", test_index)
	x_train, x_test = x[train_index], x[test_index]     
	y_train, y_test = y[train_index], y[test_index]

print('x_train', x_train.shape)
print('x_test' , x_test.shape)
print('y_train', y_train.shape)
print('y_test' , y_test.shape)


lb = LabelEncoder()

y_train = to_categorical(lb.fit_transform(y_train))
y_test = to_categorical(lb.fit_transform(y_test))


print('y_train',y_train.shape)


'''
x_train[0].flatten()

x_traincnn =np.expand_dims(x_train, axis=2)
x_testcnn= np.expand_dims(x_test, axis=2)

print('x_traincnn',x_traincnn.shape)

'''


num_rows     = 257
num_columns  = 251
num_channels = 1

leaky_relu_alpha = 0.1
#filter_size = 2

x_train = x_train.reshape(x_train.shape[0],num_rows,num_columns,num_channels)
x_test  = x_test.reshape(x_test.shape[0],num_rows,num_columns,num_channels)


print('new_train',x_train.shape)

num_labels = y_train.shape[1]

def make_dilated_network(num_rows, num_columns, num_channels):
    input_data = Input(shape=(num_rows, num_columns, num_channels))
    x = Conv2D(filters=32, kernel_size=1)(input_data)
    x = Conv2D(filters=32, kernel_size=5, padding = 'same')(x)
    x = MaxPooling2D(pool_size=2)(x)
    x = BatchNormalization()(x)
    x = LeakyReLU()(x)

    x_1 = Conv2D(filters=64, kernel_size=3, padding = 'same')(x)
    x_1 = MaxPooling2D(pool_size=2)(x_1)
    x_1 = BatchNormalization()(x_1)
    x_2 = Conv2D(filters=64, kernel_size=3, padding="same", dilation_rate=1)(x)
    x_2 = MaxPooling2D(pool_size=2)(x_2)
    x_2 = BatchNormalization()(x_2)
    x = Add()([x_1, x_2])
    x = LeakyReLU()(x)

    x_1 = Conv2D(filters=64, kernel_size=3, padding = 'same')(x)
    x_1 = MaxPooling2D(pool_size=2)(x_1)
    x_1 = BatchNormalization()(x_1)
    x_2 = Conv2D(filters=64, kernel_size=3, padding="same", dilation_rate=1)(x)
    x_2 = MaxPooling2D(pool_size=2)(x_2)
    x_2 = BatchNormalization()(x_2)
    x = Add()([x_1, x_2])
    x = LeakyReLU()(x)

    x_1 = Conv2D(filters=16, kernel_size=3, padding = 'same')(x)
    x_1 = MaxPooling2D(pool_size=2)(x_1)
    x_1 = BatchNormalization()(x_1)
    x_2 = Conv2D(filters=16, kernel_size=3, padding="same", dilation_rate=1)(x)
    x_2 = MaxPooling2D(pool_size=2)(x_2)
    x_2 = BatchNormalization()(x_2)
    x = Add()([x_1, x_2])
    x = LeakyReLU()(x)

    x = Flatten()(x)
    
    x = Dense(num_labels, activation='softmax')(x)

    model = tf.keras.Model(inputs=input_data, outputs=x, name="Dilated_STFT")
    return model


# Construct model 
model = Sequential()
model = make_dilated_network(num_rows, num_columns, num_channels)
model.summary()

#lr = tf.optimizers.schedules.ExponentialDecay(0.001, decay_steps=4498*50, decay_rate=0.95)
# Compile the model

# defining the parameters for RMSprop (I used the keras defaults here)
rms = RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)
model.compile(loss='categorical_crossentropy', metrics=['categorical_accuracy'],optimizer=rms)


# Display model architecture summary 
print(model)


# Calculate pre-training accuracy 
score = model.evaluate(x_test, y_test, verbose=1)
accuracy = 100*score[1]

print("Pre-training accuracy: %.4f%%" % accuracy)

#callback = tf.keras.callbacks.EarlyStopping(verbose=1, patience=10,min_delta=0.05)
csv_logger = CSVLogger('log.csv', append=True, separator=';')
history = model.fit(x_train, y_train, batch_size=16, epochs=100, validation_data=(x_test,y_test),callbacks=[csv_logger])


# Evaluating the model on the training and testing set
score = model.evaluate(x_train, y_train, verbose=0)
print("Training Accuracy: ", score[1])

score = model.evaluate(x_test, y_test, verbose=0)
print("Testing Accuracy: ", score[1])

plt.plot(history.history['categorical_accuracy'], label='Train Accuracy')
plt.plot(history.history['val_categorical_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.show()


#tf.keras.callbacks.EarlyStopping(patience=10, min_delta=0.05)

#score = model.evaluate(np.expand_dims(X, axis=3), y, batch_size=32)
#print score

target_names=['female_calm','male_calm','female_happy','male_happy','female_sad','male_sad','female_angry','male_angry','female_fearful','male_fearful']

y_pred = model.predict(x_test)

print('y_pred',y_pred)
print('y_pred.shape',y_pred.shape)

y_true = np.argmax(test_y, axis=1)
y_pred_classes = np.argmax(y_pred, axis=1)

test_acc = sum(y_pred == y_true) / len(y_true)
print('Test set accuracy:',test_acc)

confusion_mtx = confusion_matrix(Y_true, Y_pred_classes)





